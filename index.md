---
layout: homepage
---

## About Me

I am a PhD Candidate at Brown University where I am advised by Seny Kamara. Broadly, I research machine learning and automated decision making with the goal of ensuring that these techniques are both responsible and trustworthy. 

## Research Interests

Machine Learning, Algorithmic Fairness, Adversarial Learning, Optimal Transport

<!--
## News

- **[June. 2022]** Our paper about incremental learning is accepted to CVPR 2020.
- **[Feb. 2020]** We will host the ACM Multimedia Asia 2020 conference in Singapore!
- **[Sept. 2019]** Our paper about few-shot learning is accepted to NeurIPS 2019.
- **[Mar. 2019]** Our paper about few-shot learning is accepted to CVPR 2019.
-->

## Manuscripts

- **Achieving Downstream Fairness with Geometric Repair**
  <br>
  **Kweku Kwegyir-Aggrey**, Jessica Dai, A. Feder Cooper, Keegan Hines 
  <br>
  [[PDF](https://arxiv.org/abs/2203.07490)] 

- **Everything is Relative: Understanding Fairness with Optimal Transport**
  <br>
  **Kweku Kwegyir-Aggrey**, Rebecca Santorella, Sarah M. Brown. 
  <br>
  [[PDF](https://arxiv.org/abs/2102.10349)]


## Ongoing Projects 
- **Measuring Fairness when Protected Groups are Unkown** 
<br> __with Naveen Durvasula and John Dickerson__ 
<br> Accessing and characterizing the accuracy of fairness metrics, in the common scenario where protected attributes are difficult or impossible to obtain.    
  
  
  - **Interactive Proofs for Verifying Machine Learning Computations(( ))
  <br> __with Seny Kamara__ 
  <br> We are developing efficient protocols for verifying machine learning computations, when the prover (the party under audit) is adversarial or not fully trusted. 
  
  - **Revisiting Area Under the Curve (AUC) for Model Selection } **
  <br> __with Suresh Venkatasubramanian, Marissa Gerchick Aaron Horowitz__ 
  <br>  In this work we highlight issues with common practice of validing risk assessment models with the Area Under the Curve (AUC) metric.  
<!--
  \item \textbf{Interactive Proofs for Verifying Machine Learning Computations} with Seny Kamara.  
            
  We are developing efficient protocols for verifying machine learning computations, when the prover (the party under audit) is adversarial or not fully trusted. 
  
  \item \textbf{Revisiting Area Under the Curve (AUC) for Model Selection } with Suresh Venkatasubramanian and Aaron Horowitz.  
  
  Across many disciplines, AUC is often used as a measurement to help validate risk assessment models.  In this work we show that as a model validation metric, AUC can often obfuscate important aspects of model performance, therefore leading to the erroneous validation of models which may have disparate impact across protected groups. 
\end{enumerate}
-->
## Workshop Publications 

- **Model Selection's Disparate Impact in Real-World Deep Learning Applications**
  <br>
  Jessica Zosa Forde, A. Feder Cooper, **Kweku Kwegyir-Aggrey**,  Christopher De Sa, Michael Littman 
  <br> Science of Deep Learning Workshop (ICLR '21)  
  <br> [[PDF](https://arxiv.org/abs/2104.00606)]
